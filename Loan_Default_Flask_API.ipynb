{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vndunaga/Predicting-a-Loan-Default/blob/main/Loan_Default_Flask_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pL51xsj3tn1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Creating a dataframe from the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Loan/accepted_2007_to_2018Q4 (1).csv.gz\", compression = \"gzip\", low_memory=False)\n"
      ],
      "metadata": {
        "id": "jSAUyRkNlgRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Get unique loan statuses\n",
        "unique_loan_statuses = df['loan_status'].unique()\n",
        "\n",
        "# Initialize an empty DataFrame to store the selected data\n",
        "selected_data = pd.DataFrame()\n",
        "\n",
        "# Step 2 and 3: Select random data points for each unique loan status\n",
        "for status in unique_loan_statuses:\n",
        "    # Select all data points with the current loan status\n",
        "    data_with_status = df[df['loan_status'] == status]\n",
        "\n",
        "    # Check if there is at least one data point with the current loan status\n",
        "    if len(data_with_status) > 0:\n",
        "        # Randomly select one data point\n",
        "        random_data_point = data_with_status.sample(n=1)\n",
        "\n",
        "        # Append the selected data point to the selected_data DataFrame\n",
        "        selected_data = selected_data.append(random_data_point)\n",
        "\n",
        "selected_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Now, generate additional random samples for the remaining count (total 25 samples)\n",
        "remaining_samples = 100 - len(selected_data)\n",
        "\n",
        "# Select additional random data points from the entire dataset (without considering loan status)\n",
        "additional_samples = df.sample(n=remaining_samples)\n",
        "\n",
        "# Append the additional random samples to the selected_data DataFrame\n",
        "selected_data = selected_data.append(additional_samples)\n",
        "\n",
        "# Reset the index again after adding the additional samples\n",
        "selected_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the selected data\n",
        "selected_data.to_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "uXfY0PRSlf68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter the original dataset to include only \"Defaulters\"\n",
        "defaulters_data = df[df['loan_status'] == 'Default']\n",
        "\n",
        "# Check if there are at least 25 defaulters\n",
        "if len(defaulters_data) >= 25:\n",
        "    # Randomly select 25 defaulters\n",
        "    selected_defaulters = defaulters_data.sample(n=25, random_state=42)\n",
        "else:\n",
        "    # If there are fewer than 25 defaulters, select all available defaulters\n",
        "    selected_defaulters = defaulters_data\n",
        "\n",
        "# Reset the index of the selected_defaulters DataFrame\n",
        "selected_defaulters.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the selected defaulters data\n",
        "selected_defaulters.to_csv(\"testss.csv\")\n"
      ],
      "metadata": {
        "id": "GMhtjSOPqjmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "metadata": {
        "id": "6yhxPRrUgnlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import requests\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "        self.encoders = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        for column in self.columns:\n",
        "            encoder = LabelEncoder()\n",
        "            encoder.fit(X[column])\n",
        "            self.encoders[column] = encoder\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_encoded = X.copy()\n",
        "        for column in self.columns:\n",
        "            X_encoded[column] = self.encoders[column].transform(X[column])\n",
        "        return X_encoded\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        X_decoded = X.copy()\n",
        "        for column in self.columns:\n",
        "            X_decoded[column] = self.encoders[column].inverse_transform(X[column])\n",
        "        return X_decoded\n",
        "\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/templates')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "selected_columns = [\n",
        "    'loan_amnt', 'term', 'int_rate', 'grade', 'sub_grade', 'home_ownership',\n",
        "    'annual_inc', 'verification_status', 'purpose', 'dti',\n",
        "    'inq_last_6mths', 'pub_rec', 'revol_util', 'total_acc', 'open_acc',\n",
        "    'hardship_flag', 'mort_acc', 'open_acc_6m', 'acc_now_delinq',\n",
        "    'pub_rec_bankruptcies', 'tax_liens'\n",
        "]\n",
        "\n",
        "columns=[\"term\", \"grade\", \"sub_grade\", \"home_ownership\", \"verification_status\", \"purpose\", \"hardship_flag\"]\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/check_transaction', methods=['POST'])\n",
        "def check_transaction():\n",
        "    loan_df = request.files['transaction_file']\n",
        "    loan_df = pd.read_csv(loan_df)\n",
        "\n",
        "    loan_df_filtered = loan_df[selected_columns].copy()\n",
        "\n",
        "    # Load the Label Encoder Transformer\n",
        "    with open('/content/label_encoder_transformer.joblib', 'rb') as f:\n",
        "        transformer = joblib.load(f)\n",
        "\n",
        "\n",
        "    # loan_df_filtered[\"loan_status\"] = loan_df_filtered[\"loan_status\"].replace(cleanup)\n",
        "    # loan_df_filtered['loan_status'] = loan_df_filtered.loan_status.replace({'Paid': 1, 'Default': 0})\n",
        "\n",
        "\n",
        "\n",
        "    loan_df_filtered = loan_df_filtered.fillna(0)\n",
        "    loan_df_filtered = transformer.transform(loan_df_filtered)\n",
        "    # loan_df_cleaned = loan_df_filtered.drop(['loan_status'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Load the first model\n",
        "    rf_model = joblib.load(\"rf_model.pkl\")\n",
        "\n",
        "        # Load the second model\n",
        "    mlp_model = joblib.load(\"mlp_model.pkl\")\n",
        "\n",
        "    print(\"loan_df_filtered columns:\", loan_df_filtered.columns)\n",
        "\n",
        "        # Make predictions with the first model\n",
        "    pred1 = rf_model.predict(loan_df_filtered)\n",
        "    print(pred1)\n",
        "    # Make predictions with the second model\n",
        "    pred2 = mlp_model.predict(loan_df_filtered)\n",
        "    print(pred2)\n",
        "\n",
        "    # Initialize empty array to store results\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(pred1)):\n",
        "        if pred1[i] == 0 and pred2[i] == 0:\n",
        "            results.append(\"Defaulter\")\n",
        "        elif pred1[i] == 1 and pred2[i] == 1:\n",
        "            results.append(\"Non-Defaulter\")\n",
        "        else:\n",
        "            results.append(\"Suspecious\")\n",
        "\n",
        "      # Create a DataFrame with results and member_id (Transaction ID)\n",
        "    result_df = pd.DataFrame({\"id\": loan_df[\"id\"], \"Result\": results})\n",
        "\n",
        "    # Merge the results DataFrame with the original DataFrame on member_id\n",
        "    merged_df = loan_df.merge(result_df, on='id', how='left')\n",
        "\n",
        "    # render the HTML table with pagination\n",
        "    result_table = merged_df[[\"id\", \"Result\"]].to_html(index=False, classes=\"table table-striped\")\n",
        "    return render_template('index.html', prediction=result_table)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   app.run()"
      ],
      "metadata": {
        "id": "0ToaJ2UMtpnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}